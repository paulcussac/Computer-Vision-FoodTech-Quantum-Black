{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7dc9a-24e4-46ca-a2cc-5d8a1b3ba39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import sys\n",
    "import config\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "sys.path.append('model_building/create_image_folders.py')\n",
    "from model_building.create_image_folders import * \n",
    "sys.path.append('model_building/cnn_model_keras.py')\n",
    "from model_building.cnn_model_keras import *\n",
    "sys.path.append('model_building/new_keras_model.py')\n",
    "from model_building.new_keras_model import *\n",
    "sys.path.append('model_test/test_model.py')\n",
    "from model_test.test_model import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6b9a18-3628-4eb2-908e-91f210401e29",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88918cb2-3777-4b13-8d57-8894cb4987a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set paths\n",
    "img_folder = os.path.join(os.getcwd(),\"data\",\"ai_ready\",\"images\")\n",
    "train_img = os.path.join(os.getcwd(),\"data\",\"ai_ready\",\"train_images\")\n",
    "val_img = os.path.join(os.getcwd(),\"data\",\"ai_ready\",\"val_images\")\n",
    "test_img = os.path.join(os.getcwd(),\"data\",\"ai_ready\",\"test_images\")\n",
    "labels_image = os.path.join(os.getcwd(),\"data\",\"ai_ready\",\"x-ai_data.csv\")\n",
    "create_images =False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102801e9-5f01-4cb4-bec7-9e7f9ba2e42c",
   "metadata": {},
   "source": [
    "## Create Subfolder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da17ccb",
   "metadata": {},
   "source": [
    "Use the fonction \"subfolders\" to do the same thing as the cells below, DO NOT run it twice to avoid duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4610738-1cf4-4b2a-8ded-40d0dd15aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders(labels_image, img_folder, train_img, val_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4cb858-b1ad-4844-a7dd-87d2c0dc79e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set paths\n",
    "img_folder = \"/home/jovyan/my_work/QB/Quantum-Black-Challenge/data/ai_ready/images/\"\n",
    "train_img = \"/home/jovyan/my_work/QB/Quantum-Black-Challenge/data/ai_ready/train_images/\"\n",
    "val_img = \"/home/jovyan/my_work/QB/Quantum-Black-Challenge/data/ai_ready/val_images/\"\n",
    "test_img = \"/home/jovyan/my_work/QB/Quantum-Black-Challenge/data/ai_ready/test_images/\"\n",
    "labels_image = \"/home/jovyan/my_work/QB/Quantum-Black-Challenge/data/ai_ready/x-ai_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f1bdb-ad89-451a-8721-83615ae0b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_image = pd.read_csv(labels_image)\n",
    "train = labels_image.loc[labels_image['split']=='train']\n",
    "val = labels_image.loc[labels_image['split']=='validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d57c63-4fa7-4757-ae53-288c7c764b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train0 = train.loc[train['class']==0]\n",
    "train1 = train.loc[train['class']==1]\n",
    "\n",
    "val0 = val.loc[val['class']==0]\n",
    "val1 = val.loc[val['class']==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49927fd5-43da-4919-9407-8705f68aa659",
   "metadata": {},
   "outputs": [],
   "source": [
    "val0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4907e31e-9792-45e1-912d-d26e435437ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move TRAIN images labeled 0 to the correct folder\n",
    "\n",
    "for i in train0.index:\n",
    "    im = cv2.imread(img_folder+train0.loc[i,'filename'])\n",
    "    cv2.imwrite(train_img + '0/' +train0.loc[i,'filename'], im)\n",
    "#Move TRAIN images labeled 1 to the correct folder\n",
    "for i in train1.index:\n",
    "    im = cv2.imread(img_folder+train1.loc[i,'filename'])\n",
    "    cv2.imwrite(train_img+'1/' +train1.loc[i,'filename'], im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072867bb-f74a-4512-b0c6-b3f7dc18b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move val images labeled 0 to the correct folder\n",
    "for i in val0.index:\n",
    "    im = cv2.imread(img_folder+'/'+val0.loc[i,'filename'])\n",
    "    cv2.imwrite(val_img + '/0/' +val0.loc[i,'filename'], im)\n",
    "#Move val images labeled 1 to the correct folder\n",
    "for i in val1.index:\n",
    "    im = cv2.imread(img_folder+'/'+val1.loc[i,'filename'])\n",
    "    cv2.imwrite(val_img+'/1/' +val1.loc[i,'filename'], im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ec78c-a0d0-4087-b55e-2e62f8721e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "##Remove hidden file\n",
    "shutil.rmtree(train_img+\".ipynb_checkpoints\")\n",
    "shutil.rmtree(val_img+\".ipynb_checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04342dc-aaf4-4080-95eb-d9b17535ac88",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d239954-82a8-41be-99df-59c49ef5e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train and Val dataset\n",
    "tf.config.list_physical_devices()\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "train_ds = train(train_img, config.image_size, config.batch_size)\n",
    "val_ds = val(val_img, config.image_size, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c06133-847f-40cd-a951-f3a3bcb5c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_ds.__getitem__(3):\n",
    "images, labels = train_ds.__getitem__(1)\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(2, 2, i + 1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(int(labels[i]))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c3ba38-785c-4bbf-a415-ec82cb0057c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "model = make_model(input_shape=config.image_size + (3,), num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a425d-73d4-440d-a71a-e158b8c0a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_ds, val_ds, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf7c30-6672-453c-8d44-e1f229dd99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a03c1-b31e-4f3a-a01c-1c737fe547e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize data augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomContrast([0,1]),\n",
    "        layers.RandomTranslation(height_factor=0.2, width_factor=0.2)\n",
    "    ]\n",
    ")\n",
    "plt.figure(figsize=(10, 10))\n",
    "images, _ in train_ds.__getitem__(4)\n",
    "# for images, _ in train_ds.take(1):\n",
    "for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow((255*augmented_images[0].numpy()).astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95f9e96-bd86-46c1-bcc5-ee24e86f3c4a",
   "metadata": {},
   "source": [
    "## Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001df99d-e28b-4ebf-af91-51e6c005158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = labels_image.loc[labels_image['split']=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f3492-7224-498d-a9fe-b13d20bd8954",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3483a22-667b-42d0-b365-e9e0bec342f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move TEST images to the correct folder, only run once: create a test folder with another test folder with all the images inside\n",
    "for i in test.index:\n",
    "    im = cv2.imread(os.path.join(img_folder,test.loc[i,'filename']))\n",
    "    # cv2.imwrite(test_img + 'test/' + test.loc[i,'filename'], im)\n",
    "    # im = cv2.imread(os.path.join(img_folder, val1.loc[i, \"filename\"]))\n",
    "    cv2.imwrite(os.path.join(test_img, \"test\", test.loc[i, \"filename\"]), im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e581e9-cc89-445e-b354-e7c67ff0706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "shutil.rmtree(test_img+\"test/.ipynb_checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee32151-3bb6-4f68-b35d-30d338e14dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from PIL import Image\n",
    "\n",
    "image = load_img(os.path.join(img_folder,'silos_256-0-0--6-16-536-28464.png'))\n",
    "data = img_to_array(image)\n",
    "samples = np.expand_dims(data, 0)\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "   preprocessing_function = myFunc,\n",
    "    )\n",
    "\n",
    "# Creating an iterator for data augmentation\n",
    "it = datagen.flow(samples, batch_size=1)\n",
    "\n",
    "# Preparing the Samples and Plot for displaying output\n",
    "for i in range(2):\n",
    "    # preparing the subplot\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(3, 2,i+1)\n",
    "    # generating images in batches\n",
    "    batch = it.next()\n",
    "    # Remember to convert these images to unsigned integers for viewing \n",
    "    img = batch[0].astype('uint8')\n",
    "    # Plotting the data\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadda0aa-62e5-43c5-a41a-f9a36b81d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_img(os.path.join(img_folder,'silos_256-0-0--6-16-536-28464.png'))\n",
    "data = img_to_array(image)\n",
    "samples = np.expand_dims(data, 0)\n",
    "\n",
    "#Plot the batch images w.r.t. the dataset images.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.axis('off')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f597b3d-cbf2-4b70-9900-86d3d26312b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from PIL import Image\n",
    "\n",
    "image = load_img(os.path.join(img_folder,'silos_256-0-0--6-16-536-28464.png'))\n",
    "image = img_to_array(image).astype(int)\n",
    "data = np.expand_dims(image, 0)\n",
    "\n",
    "def myFunc(image):\n",
    "    return cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "                        #COLOR_RGB2HSV)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        rotation_range=90,\n",
    "        # shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        zca_whitening =True,\n",
    "        # # brightness_range = [0.5, 2.0],\n",
    "        preprocessing_function = myFunc,\n",
    "        )\n",
    "\n",
    "# Creating an iterator for data augmentation\n",
    "it = datagen.flow(data, batch_size=1)\n",
    "\n",
    "# Preparing the Samples and Plot for displaying output\n",
    "for i in range(6):\n",
    "    # preparing the subplot\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    # generating images in batches\n",
    "    batch = it.next()\n",
    "    # Remember to convert these images to unsigned integers for viewing \n",
    "    image = batch[0].astype('uint8')\n",
    "    # Plotting the data\n",
    "    pyplot.imshow(image)\n",
    "\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88621a80-d503-4c9a-bbdd-85e1d3f40c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train, Val, and Test dataset\n",
    "train_ds = train_set(train_img, config.image_size, config.batch_size)\n",
    "val_ds = val_set(val_img, config.image_size, config.batch_size)\n",
    "test_ds = test_set(test_img, config.image_size, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30763939-709b-40da-bd25-60bd3ce1436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_model(config.input_shape, train_ds, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bf7d67-c677-430b-9ee5-1fc8a47955d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(\"last_keras_model\", train_ds, val_ds, config.number_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f8e4e2-5450-41cf-a201-5aea2c4139e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras = load_model(\"last_keras_model.h5\")\n",
    "preds = test_model(test_ds, model_keras, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfccf75-4c02-4938-9e0a-99a2ef9a0558",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_preds(preds, train_ds, test_ds, 'last_keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c250ce6-70d5-4036-a381-b9c9e1fdf318",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('last_keras_model.h5')\n",
    "\n",
    "test_ds = test_set(test_img, config.image_size, config.batch_size)\n",
    "y_preds = test_model(test_ds, model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad24b2-8392-4eee-98e5-c5dc834c67d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = labels_image[labels_image['split']==\"test\"]['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ab8f5-5138-4414-9885-0cb7409d9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc, roc_auc_score,accuracy_score\n",
    "\n",
    "f1_score_test = f1_score(y_test, 1*(y_preds>0.5))\n",
    "accuracy_test = accuracy_score(y_test, 1*(y_preds>0.5))\n",
    "print(f\"the f1_score test is {f1_score_test}, the accucary is {accuracy_test}\")\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_preds)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7492954-4a72-4a70-b4ae-975a62b8fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = labels_image[labels_image['split']==\"test\"].copy()\n",
    "df_preds[\"preds_proba\"] = y_preds\n",
    "df_preds.to_csv('df_preds.csv')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, color='#285430', label = f'AUC = {roc_auc :0.2f}')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],color='#fed049',linestyle='--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig('auc_curve')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecec9d0c-bc92-4284-908a-7848a3b67e5a",
   "metadata": {},
   "source": [
    "## With TEST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971891da-3d92-47fd-ba3f-50fd1219f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set paths\n",
    "img_folder = os.path.join(os.getcwd(),\"data\",\"ai_ready\",\"images\")\n",
    "train_img = os.path.join(os.getcwd(),\"data\",\"ai_ready\",\"train_images\")\n",
    "val_img = os.path.join(os.getcwd(),\"data\",\"ai_ready\",\"val_images\")\n",
    "test_img = os.path.join(os.getcwd(),\"data\",\"ai_ready\",\"test_images\")\n",
    "labels_image = os.path.join(os.getcwd(),\"data\",\"ai_ready\",\"x-ai_data.csv\")\n",
    "create_images =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff54e7-6149-47b7-8dcf-6e989a5415b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train, Val, and Test dataset\n",
    "train_ds = train_set(train_img, config.image_size, config.batch_size)\n",
    "val_ds = val_set(val_img, config.image_size, config.batch_size)\n",
    "test_ds = test_set(test_img, config.image_size, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45000fb6-433e-44e4-ae87-5d9796f13c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('keras_model_theo.h5')\n",
    "\n",
    "test_ds = test_set(test_img, config.image_size, config.batch_size)\n",
    "y_preds = test_model(test_ds, model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e440b-ee64-4455-b649-c4eb9e45de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_preds(y_preds, train_ds, test_ds, 'predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceca4bb-4dd3-4884-87c7-8e6f7869dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices= np.round(y_preds).astype(int)\n",
    "labels = (train_ds.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices[:,0]]\n",
    "\n",
    "filenames=test_ds.filenames\n",
    "results=pd.DataFrame({\"filename\":filenames,\n",
    "                      \"class_predicted\":predictions})\n",
    "\n",
    "results['filename'] = results['filename'].apply(lambda element: element.split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccee186-0e26-4446-897d-ca4b0e19a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values('filename', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f732715d-e3c5-4e49-ba89-4b16218cf03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[results['class_predicted']=='0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10cac59-ecad-4577-a245-fe3d0aeb23b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4b1a4a749a8d48ef741ed32095ab3a7e8b65ab1c4196700a52abd92786a361c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
